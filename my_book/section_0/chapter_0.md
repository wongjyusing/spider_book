## 什么是爬虫？
这个问题，你谷歌或者百度到的答案都是文绉绉的。  
说什么，爬虫是**网络机器人**、**网络蜘蛛**，**蚂蚁**、**自动索引程序**。  
然后一大段让新手，菜鸟看不懂的文字。  
让我直接用文字、语言回答的话，我也回答不上来。  
但是，我会用例子来讲解什么是爬虫。  
## 例子
请大家到我的[GitHub仓库](https://github.com/wongjyusing/spider_book)里面下载一个项目。  
具体的使用方法可以阅读里面的**README.md**。  
当这个项目运行起来后。通过浏览器打开[http://127.0.0.1:8000/](http://127.0.0.1:8000/)的话.   
可以看到这个是金庸先生的小说网站。  

在讲解什么是爬虫之前。  
我们先把**什么是爬虫？**这个问题转化成**为什么需要爬虫？**   

## 任务  
现在有个任务给你：  
把在[http://127.0.0.1:8000/](http://127.0.0.1:8000/)上看到的所有小说（一共有45本）  
按照版本生成一个文件夹（修订版、新修版、旧版）  
然后根据书名生成一个txt文件（神雕侠侣.txt、射雕英雄传.txt、天龙八部.txt、小李飞刀.txt）  
最后通过复制粘贴成45本完整的小说。  

### 正常做法
如果要完成这样的任务，通常我们的做法是：  
1、 浏览器打开[http://127.0.0.1:8000/](http://127.0.0.1:8000/)，看到有3个版本，每个版本有15本小说。总共有45本小说。  
2、 在桌面上创建一个名为**修订版**的文件夹。  
3、 点击页面上的[神雕侠侣小说](http://127.0.0.1:8000/chapter/shen)，然后在修订版的文件夹创建一个**神雕侠侣小说.txt**文件。   
4 、点击[第一回 风月无情](http://127.0.0.1:8000/detail/shen/1),复制章节名到神雕侠侣小说.txt中，然后复制整个网页中的小说内容。  
5、点击[第二回 故人之子](http://127.0.0.1:8000/detail/shen/2),复制章节名到神雕侠侣小说.txt中，然后复制整个网页中的小说内容。  
6、点击[第三回 求师终南](http://127.0.0.1:8000/detail/shen/3),复制章节名到神雕侠侣小说.txt中，然后复制整个网页中的小说内容。  
……  
上面的步骤大概需要重复3800次以上，才能完成这个任务。  

### 使用爬虫  
使用爬虫的话，步骤如下：  
1、 浏览器打开[http://127.0.0.1:8000/](http://127.0.0.1:8000/)，观察这个网页的构成和里面小说章节页面的规律。  
2、 浏览器打开[神雕侠侣小说](http://127.0.0.1:8000/chapter/shen)、[书剑恩仇录小说](http://127.0.0.1:8000/chapter/shu)、[天龙八部小说](http://127.0.0.1:8000/chapter/otian)、[小李飞刀](http://127.0.0.1:8000/chapter/xiaolifeidao)等章节页面，分析小说内容页的规律和构成。（这个网站肯定是没有小李飞刀的页面的，为什么要打开的原因后面的内容会讲到）  
3、 浏览器打开[第一回 风月无情](http://127.0.0.1:8000/detail/shen/1)，分析小说章节名和内容的构成。  
4、用ruby、python、node.js或者go等程式语言根据之前的**分析** ，写一段代码，任务完成。  

## 爬虫是什么？？
结合上面的例子，爬虫就是一段程式或者说代码，用来模拟人类在浏览网页，并获取我们需要的信息。减轻我们的劳动。  
注意，爬虫也属于是一种攻击手段。会影响到网站的正常工作，例如说会影响到正常访问该网站的用户打开网页的速度。  
所以，我做了这样的项目，让大家自己爬自己。不影响他人。后续也会做出一系列**坑死人不偿命**的反爬机制的项目。  
